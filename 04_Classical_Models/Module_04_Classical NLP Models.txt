==================================
Module ৪: Classical NLP Models
==================================

১. Text Classification:
--------------------------
সহজ কথায়, একটি টেক্সট বা লেখাকে পড়ে সেটি কোন গ্রুপের বা ক্যাটাগরির অন্তর্ভুক্ত,
তা বের করাই হলো টেক্সট ক্লাসিফিকেশন।

কিছু জনপ্রিয় উদাহরণ:
=> Spam Detection: ইমেইলটি কি স্প্যাম (Spam) নাকি স্প্যাম না (Ham)?
=> Sentiment Analysis: কাস্টমার রিভিউটি কি পজিটিভ (ভালো) নাকি নেগেটিভ (খারাপ)?
=> Topic Classification: নিউজটি কি খেলার খবর, রাজনীতির খবর, নাকি বিনোদনের?



২. অ্যালগরিদম পরিচিতি:
--------------------------
এই ক্লাসিফিকেশন করার জন্য আমরা ৩টি জনপ্রিয় অ্যালগরিদম ব্যবহার করি। খুব সহজ ভাষায় এদের কাজ করার স্টাইলটা বলি:

১. Naive Bayes
এটি সম্পূর্ণ Probability (সম্ভাবনা) বা মডিউল ০-এর ম্যাথের ওপর ভিত্তি করে কাজ করে।
কাজ করার স্টাইল: সে দেখে, "লটারী জিতেছে" শব্দগুলো থাকলে ইমেইলটি স্প্যাম হওয়ার সম্ভাবনা কত?
আবার "মিটিং আছে" থাকলে স্প্যাম না হওয়ার সম্ভাবনা কত?
ব্যবহার: টেক্সট ক্লাসিফিকেশনে এটি সবচেয়ে দ্রুত এবং জনপ্রিয়।

২. Logistic Regression
নামে রিগ্রেশন থাকলেও এটি আসলে ক্লাসিফিকেশন করে।
কাজ করার স্টাইল: সে ডেটার মাঝখানে একটা সোজা দাগ বা দেয়াল (Decision Boundary) টেনে দেয়।
দেয়ালের একপাশে যারা পড়ে তারা "পজিটিভ", অন্যপাশে যারা পড়ে তারা "নেগেটিভ"।

৩. Support Vector Machine
এটি লজিস্টিক রিগ্রেশনের মতোই দাগ টানে, তবে একটু স্মার্টলি।
কাজ করার স্টাইল: সে শুধু দাগ টানে না, সে চেষ্টা করে দুই গ্রুপের মাঝখানের দূরত্ব (Margin) যেন সবচেয়ে বেশি হয়। 
অর্থাৎ সে দুই গ্রুপের মাঝখানে একটা চওড়া রাস্তা তৈরি করে, যাতে ভুল হওয়ার সম্ভাবনা কমে যায়।



৩. Model Evaluation
--------------------------
আমরা মডেল বানালাম, কিন্তু মডেলটা ভালো না খারাপ বুঝব কীভাবে? শুধু Accuracy (সঠিকতার হার) দিয়ে বিচার করলে
ভুল হতে পারে।

=> কেন? 
==> একটা উদাহরণ দিই: 
ধরো, ১০০টা ইমেইলের মধ্যে ৯৯টাই ভালো ইমেইল, মাত্র ১টা স্প্যাম। আমার বোকা মডেল যদি চোখ বন্ধ করে সব 
ইমেইলকে "ভালো" বলে দেয়, তাহলেও তার Accuracy হবে ৯৯%! (কারণ সে ৯৯টা সঠিক বলেছে)। 
কিন্তু সে আসল কাজটাই (স্প্যাম ধরা) করতে পারেনি।

তাই আমরা নিচের মেট্রিকগুলো ব্যবহার করি:
১. Confusion Matrix: একটা টেবিল যা দেখায় মডেল কয়টা সঠিক এবং কয়টা ভুল করেছে।
২. Precision: যখন মডেল বলে "এটা স্প্যাম", তখন সেটা আসলে কতটা সত্য? (মিথ্যা অপবাদ দিচ্ছে না তো?)
৩. Recall: আসল যতগুলো স্প্যাম ছিল, তার মধ্যে কয়টা সে ধরতে পেরেছে? (কোনো চোর যেন পালিয়ে না যায়)
৪. F1-Score: Precision এবং Recall-এর গড়। এটা দিয়ে বোঝা যায় মডেলটা সবদিক দিয়ে ব্যালেন্সড কিনা।

-----------------------------------------------------------------------------------------
তোমার সামনে ৪ ধরনের ঘটনা ঘটতে পারে। এই ৪টি ঘটনাই হলো "কনফিউশন ম্যাট্রিক্সের ৪টি ঘর"
-----------------------------------------------------------------------------------------

১. True Positive (TP) - "সত্যিই পজিটিভ"
ঘটনা: রোগীর আসলে ডেঙ্গু আছে। তুমিও রিপোর্টে বলেছ "পজিটিভ" (আছে)।
ফলাফল: তুমি সঠিক! রোগী সঠিক চিকিৎসা পাবে।
মনে রাখার উপায়: True (সঠিক বলেছি) + Positive (রোগ আছে বলেছি)।

২. True Negative (TN) - "সত্যিই নেগেটিভ"
ঘটনা: রোগীর আসলে ডেঙ্গু নেই (সে সুস্থ)। তুমিও রিপোর্টে বলেছ "নেগেটিভ" (নেই)।
ফলাফল: তুমি সঠিক! রোগী খুশি মনে বাড়ি যাবে।
মনে রাখার উপায়: True (সঠিক বলেছি) + Negative (রোগ নেই বলেছি)।

৩. False Positive (FP) - "ভুল পজিটিভ" (False Alarm)
ঘটনা: রোগীর আসলে ডেঙ্গু নেই। কিন্তু তুমি ভুলে বলেছ "পজিটিভ" (আছে)।
ফলাফল: রোগী ভয় পেয়ে যাবে, অকারণে ওষুধ খাবে। কিন্তু সে "মারা" যাবে না। একে বলে Type 1 Error।
মনে রাখার উপায়: False (ভুল বলেছি) + Positive (রোগ আছে বলেছি)।

৪. False Negative (FN) - "ভুল নেগেটিভ" (Dangerous)
ঘটনা: রোগীর আসলে ডেঙ্গু আছে। কিন্তু তুমি ভুলে বলেছ "নেগেটিভ" (কিছু হয়নি, আপনি সুস্থ)।
ফলাফল: এটা মারাত্মক! রোগী ভাববে সে সুস্থ, সে চিকিৎসা নেবে না এবং বাসায় গিয়ে মারাও যেতে পারে।
একে বলে Type 2 Error।
মনে রাখার উপায়: False (ভুল বলেছি) + Negative (রোগ নেই বলেছি)।